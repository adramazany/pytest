{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72907323-3bd2-4c33-abc2-09f79497a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  langchain_community\n",
    "!pip install unstructured\n",
    "!pip install \"unstructured[docx]\"\n",
    "!pip install langchain_chroma\n",
    "!pip install -U langchain-ollama\n",
    "!pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0c055d-86fe-4ebd-a70c-73c27d76deb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"./data\", glob=\"**/*.docx\") # \n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7a668c-a105-4464-a9f1-0080890175b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b3dbd9-8b71-4c41-b92e-a73ab5094c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"llama3.2:latest\"\n",
    "# model = \"all-minilm:latest\"\n",
    "model = \"llama3.2:1b-instruct-q2_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714b49da-9092-452c-846d-1b99fdf3674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramezania\\AppData\\Local\\Temp\\ipykernel_4512\\3767905915.py:7: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding=OllamaEmbeddings(model=model, show_progress=True),\n",
      "OllamaEmbeddings: 100%|████████████████████████████████████████████████████████████████| 70/70 [01:28<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings #  The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0.\n",
    "#from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=OllamaEmbeddings(model=model, show_progress=True),\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7049b2cc-2e43-4171-986a-32b2fd9c0d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='5152803e-a221-460f-9ad5-6457dddce157', metadata={'source': 'data\\\\Concept Palamax AI.docx'}, page_content='Using AI to summarize reports generated by PalaMax or even generate reports using NLP from the data that are shown in Production view page. This can help to streamline the process of production optimization or finding bottlenecks in production.\\n\\nFuture KPI’s prediction\\n\\nUsing AI to show possible future KPI’s figures based on previous values. This can help to predict future production or help customer to plan production more effectively.\\n\\n\\n\\nExtensions\\n\\nProcess Optimization:'),\n",
       " Document(id='ccb14a5a-f0ef-4131-b75f-8c7a0d2eae41', metadata={'source': 'data\\\\Concept Palamax AI.docx'}, page_content='SpaCy is one of the newer open-source NLP processing libraries. This Python library performs quickly and is well-documented. It is able to handle large datasets and provides users with a plethora of pre-trained NLP models. SpaCy is geared toward those who are getting text ready for deep learning or extraction.\\n\\n\\n\\nFuture KPI’s prediction'),\n",
       " Document(id='1098b852-d968-4e26-8224-198638492ffa', metadata={'source': 'data\\\\Concept Palamax AI.docx'}, page_content='in accordance with the conditions of the agreement.'),\n",
       " Document(id='39a4e14a-4c72-428b-b45f-0ff21af3a8de', metadata={'source': 'data\\\\Concept Palamax AI.docx'}, page_content='management.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is Recipe?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6587b5-96d3-4665-b987-919e11eb22b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramezania\\AppData\\Local\\Temp\\ipykernel_4512\\2610587660.py:6: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=model)# \"all-minilm:latest\\\" does not support generate\"\n",
      "C:\\Development\\Python311\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = Ollama(model=model)# \"all-minilm:latest\\\" does not support generate\"\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1bc303-f97a-4e5d-82f2-7ead54f036e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I don\\'t have any information on a book called \"Gené is Missing\". The provided context appears to be related to an artificial intelligence (AI) smart factory, not a book.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the story of 'Gené is Missing' book?\"\n",
    "qa_chain.invoke(question)\n",
    "qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b7dc30-2b0a-4869-a467-43b4ab01c63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001D083883DD0>, search_kwargs={})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])\n",
       "| Ollama(model='llama3.2:1b-instruct-q2_K')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who is Arslan?\"\n",
    "qa_chain.invoke(question)\n",
    "qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c15c1-b696-4615-a0bd-937eac727ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9210b-f277-4af0-8534-58403f431c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
